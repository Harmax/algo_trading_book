% !TEX root = ../../book.tex
%\hfill
%\par\vspace{\baselineskip}

\chapter{Electronic Exchanges and Dynamics of Limit Order Books}


Stoll (2006)~\cite{hstoll} in an instructive essay traces the evolution of trading that started under a tree in 1792 with 24 brokers. This has become later on the New York Stock Exchange (NYSE). Modern electronic technology has changed how trading is done. Now all transactions are carried out though a computer system with little human intervention (see the snapshots of NYSE over two different decades).
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/pit_trading.png} 
   	\caption{Treasury bind pit 1989. \label{fig:pittrade}}
	\end{figure}
	\begin{figure}[!ht]
	   \centering
	   \includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/electronic_trading.png} 
	   \caption{The NYSE trading floor in August 2008. \label{fig:electrade}}
	\end{figure}
This has also changed how stock market trading is done. The Electronic Communication Networks (ECN) automate the trading process but the fundamental functions of trading are not changed except for the instant dissemination of the demand and supply information to all investors. The identity of traders is kept anonymous. Executions are done fast and very complex orders can now be submitted to the market. The trading costs---both direct such as commissions, brokerage fees, etc. and indirect cost due to price-impact---are expected to be lower. Over the period of two decades (1980--2000), the commissions have have gone down from 1.2\% to 0.2\%. But with higher turnover and thus with increased volume, the total commissions have increased four-fold. The reduction in bid-ask spread although may be primarily due to tick size is accelerated under electronic trading. 


It must be observed that electronic trading does not necessarily imply automated trading. But it has certainly led to more automated trading due to easy execution of the algorithms. Although there is a concern that the traders can game the prices, but computer audit trails can be used to monitor unlawful behaviors. The debate over whether electronification of trading will lead to more consolidation or fragmentation has favored the latter. The apprehension over the possibility of inefficient price formation due to fragmentation is empirically shown not to hold. The order protection rule (SEC 2005) that dictates that an order submitted to any market should get the best of prices in all markets. 


Thus large number of equity and derivative markets are now organized as electronic limit order books. The Electronic Communications Networks (ECNs) in the United States, Hong Kong and Toronto Stock Exchanges are examples of equity markets. Chicago Mercantile Exchange's (CME) Globex platform, Euronext Liffe's centralized limit order book are example of derivative markets. Open limit order books have become popular due to the greater transparency of the market when compared with dealer market settings, that rely upon the information on the dealers' best quotes. The limit order book provides its users to view the depth of the book at various price level away from the best quotes. In dealer market prices for trades beyond the quoted size must be obtained through negotiation with market maker. 


There has been a great deal of interest in studying the information content of an open limit order book and if it helps investors in tracking short-term price predictions. Assuming that the market consists of informed and noise traders, and the informed traders actively submit market orders, Glosten (1994)~\cite{glosten94} and Seppi (1997)~\cite{seppi97} argue that the order book does not contain any information beyond the best bid and best offer. But other studies such as Harris and Panchapagesan (2005)~\cite{harrispan} argue that the order book is informative and specialists better use the book information to their advantage than the traders who routinely place limit orders. In this chapter we discuss the feature of limit order book and various levels of information that have been made available to the investors; the focus is on developing models for studying the dynamics on the book and how the models could be used for high frequency trading. 


An excellent survey paper by Parlour and Seppi (2008)~\cite{parseppi} reviews the issues related to limit order markets. A limit order for any asset `$j$' is an  ex ante pre-commitment $(t,x,p)$ made at time `$t$' to trade `$x$' units at a pre-specified limit price, `$p$'. The order remains valid until it is filled or cancelled. With multiple exchanges, the interactions are quite complex; the dynamic nature of state of the order book and the choice of actions in anticipation of the future states make the limit order placement decisions, $(t,x,p)$ challenging. The key issues in the study of LOB are nicely summarized in Parlour and Seppi (2008)~\cite{parseppi}. They relate to, Price Formulation (How limit order markets differ from dynamic dealer markets?), Liquidity (Implication of the quotes posted at various depths in LOB), Dynamics (Dependencies of Various Trading Decisions), Information Aggregation (How forward-looking is the activity in LOB about future order flow in aggregate?) and Inter-Market Competition (How effective are limit order markets to induce competition and how they handle non-market frictions?). How multiple exchanges can sustain competitive pressure to attract postings to their venues? How do limit order markets help reduce market frictions? These issues are addressed in this chapter but our focus is always on how the information flow through LOB dynamics helps trading decisions. The tools we review here in this chapter can be useful to that end. 


\section{Limit Order Book (LOB):  Basic Description and Characteristics}


In automated continuous double auction trading system that have have become prevalent in the financial markets, buyers and sellers submit limit orders electronically; orders are then matched and executed as per time and price priorities. The unmatched orders are stored in the limit order book (LOB). The market orders are orders seeking the best available price and they are execute immediately. Thus, one way or other all executed orders can be taken as market orders.


The state of the order book changes quite rapidly due to high frequency program trading. There are six types of events, three on either side that can alter the state of the order book:
	\begin{itemize}
	\item Limit order submission: A limit order is added to the queue at the specified price level.
	\item Limit order cancellation: An outstanding limit order is expired or cancelled and therefore is removed from the LOB.
	\item Market order submission: Outstanding limit order at the best price are executed against the market order and thus removed from the book.
	\end{itemize}


Orders on the buy side are called ``bids'' while those on the sell side are called ``asks.'' The above events illustrated in the following diagrams.
	\begin{figure}[!ht]
	   \centering
	   \includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/limitbk1.png} 
	   \caption{Limit Order Book---Limit Bid. \label{fig:limbk1}}
	\end{figure}
	\begin{figure}[!ht]
	   \centering
	   \includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/limitbk2.png} 
	   \caption{Limit Order Book---Market Bid. \label{fig:limbk2}}
	\end{figure}
When a market order is submitted, it decreases the number of outstanding orders at the opposite best price. For example, if a market bid order arrives, it will decrease the number of outstanding asks at the best price.
	\begin{figure}[!ht]
	   \centering
	   \includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/limitbk3.png} 
	   \caption{Limit Order Book---Ask Cancellation. \label{fig:limbk3}}
	\end{figure}
All unexecuted limit orders can be cancelled. When a cancellation occurs, it will decrease the number of outstanding orders at the specified price level. 


The limit orders constitute a very significant percentage (70\%) of stock market trading activity. The main advantage of a limit order is that there is no price risk, that is when the order is executed the limit price is attained. But the execution is not guaranteed and the time to get an order executed depends on various market factors. The trade off between the limit order and the market order depends on the investors need for liquidity and the probability of execution of a limit order. The execution of limit orders does affect how the quotes are posted and are updated. A market order will be filled at or close to National Best Bid and Offer (NBBO). If the size of the order exceeds the number of shares available, it is usually split and is executed at different prices until the order is filled. The market orders are usually restricted to be filled within a day and order placed after the markets close are entered the next day at 9:30~am EST. Other types include stop-limit orders and trailing stop orders. The former type is typically used to trade a security at a specified limit price once it is traded through a specified stop price. If the stock declines in value and traders below or at the stop price, the order will become a limit order rather than a market order. The trailing stop order is in which the specified price will trail by a certain percentage from the best bid or best ask. These rules are handled in the brokers IT technology. In addition to time and duration specifications, other conditions that can be added are: fill or kill (the order gets filled in its entirety or not filled at all) or minimum quantity (if the specified minimum is not available, the order does not get executed).  
























\section{Data from LOB and Relevant Questions}


Initially researchers studying the dynamic of LOB had to content with Trades and Quotes (TAQ) data which provide a time-stamped sequence of trades (Market Orders) and updates in the price and depth of bid and ask quotes. No other information beyond the best bid and the best offer are made available. Moreover, the updates contain changes at the two quotes and were aggregated. The aggregation was clearly a limiting factor as one could not discern the kind of events that led to the changing status of the book. The level II data that became available is a time-stamped sequence of trades and quotes for the top 5-levels of the LOB. This data is little deeper than TAQ data, but was still in aggregated form. But recently made available level III data contains time-stamped sequence of all (except for hidden orders) events that occur in the LOB. Every order is identified by a unique order-id and thus it can be tracked to its lifetime. \\


\noindent\textbf{Description of Level III data:} The dataset consist of activities during the entire trading session, including early and late hours from 6:00~A.M. to 8:00~P.M. EST in a trading day. It provides intraday depth book activity for 12000 tickers from major national exchanges: Nasdaq, Direct Edge, NYSE, ARCA and BATS (exact number of exchanges depends on the historical period). All messages are consolidated into one file ordered by timestamp. This data allows to build a full national depth book at any moment intraday. The description of the level III data is given in Table~\ref{tab:level3data}. \\
	\begin{table}[!ht]
	\centering
	\begin{tabular}{lp{0.8\textwidth}} \hline
	Variable & Description \\
	& \\
	Timestamp: & Number of milliseconds after the midnight. \\
	& \\
	Ticker: & Equity symbol (up to 8 characters) \\
	& \\
	Order: & Unique order ID. \\
	& \\
	T & Message type. Allowed values: \newline \begin{minipage}[t]{0.6\textwidth} \begin{itemize} \item ``B''---Add buy order \item ``S''---Add sell order \item ``E''---Execute outstanding order in part \item ``C''---Cancel outstanding order in part \item ``F''---Execute outstanding order in full \item ``D''---Delete outstanding order in full \item ``X''---Bulk volume for the cross event \item ``T''---Execute non-displayed order \end{itemize} \end{minipage} \\
	& \\
	Shares & Order quantity for the ``B'', ``S'', ``E'', ``X'', ``C'', ``T'' messages. Zero for ``F'' and ``D'' messages. \\
	& \\
	Price & Order price, available for the ``B'', ``S'', ``X'' and ``T'' messages. \newline Zero for cancellations and executions. The last 4 digits are decimal digits. The decimal portion is padded on the right with zeros. The decimal point is implied by position; it does not appear inside the price field. Divide by 10000 to convert into currency value. \\ 
	& \\
	MPID & Market Participant ID associated with the transaction (4 characters) \\
	& \\
	MCID & Market Center Code (originating exchange---1 character) 
	\end{tabular}
	\caption{Level III data \label{tab:level3data}}
	\end{table}
	

\noindent\textbf{Special types of orders:} While the display and issuance of new ID to the modified order varies from exchange to exchange, we provide a brief description of these orders below:

\begin{enumerate}[1.]
\item Order subject to price sliding: the execution price could be one cent worse than the display price at NASDAQ; it is ranked at the locking price as a hidden order, and displayed at the price one minimum price variation (normally 1 cent) inferior to the locking price. New order ID will be used if the order is replaced as a display order. At other exchanges the old order ID will be used.

\item Pegged order: Based on NBBO, not routable, new timestamp upon re-pricing, display rules vary over exchanges.

\item Mid-point peg order: Non-displayed, can result in half-penny execution.

\item Reserve order: displayed size is ranked as a displayed limit order and the reserve size is behind non-displayed orders and pegged orders in priority. The minimum display quantity is 100 and this amount is replenished from the reserve size when it falls below 100 shares. A new timestamp is created and the displayed size will be re-ranked upon replenishing.

\item Discretionary order: displayed at one price while passively trading at a more aggressive discretionary price. The order becomes active when shares are available within the discretionary price range. Ranked last in priority. The execution price could be worse than the display price.

\item Intermarket sweep order: order that can be executed without the need of checking the prevailing NBBO.  
\end{enumerate}


Some key measures of the LOB are: relative position of an order from the top position of the side (buy or sell), the depth which is the total number of shares at a given price and the depth profile of the book reflects the depth of both prices. Large market orders can shift the bid and ask prices. If the limit price of a new order crosses the best price on the opposite side of the book, it is executed immediately and these are termed as crossing or marketable limit orders. These are used at times to explore the existence of hidden orders.


The limit order book data provides a rich source of information to better understand the market microstructure. The information is also useful for developing trading strategies. Some key issues that may be explored are:

\begin{itemize}
\item The pattern of inter-arrival times of various events.
\item Arrival and cancellation rates as a function of distance from nearest touch price.
\item Arrival and cancellation rates as a function of other available information, such as in the queue on either side of the book.
\end{itemize}

The key issues from the trading point of view are:

\begin{itemize}
\item What is the impact of market order on the limit order book?
\item What are the chances for a limit order to move up the queue from a given entry position?
\item What is the probability of making the spread?
\item What is the direction of the price movement in short duration?
\end{itemize}


\section{Models for LOB dynamics, based on Level I and Level II data}


Before we formally present the models, we want to provide a review of how the analysis of LOB data has been approached. Biais, Hillion and Spatt (1995)~\cite{spalt} study the trading activity in Paris Bouse (a fully automated limit order market), the dynamics of order flow and how the order flow varies with the state of the order book and marketplace events relevant to the asset. It is found that the conditional probability of a limit order placement is larger when the bid-ask spread is larger and when the order book is not deep. If a market order has been placed the chance that the next order posted provides liquidity is generally higher. The placement of orders also follows a pattern with new orders coming in the morning when the price discovery occurs and cancellations and large orders occur in the evenings. The durations between trades do indicate that the intensity of trade varies during the course of a day. The main tool used in these calculations is contingency table which provides both marginal and conditional probabilities. \\

\noindent \textbf{Slope of LOB:} To begin with we can consider the slope of the order book both on the demand side and on the supply side using the quotes on both sides various depths (see Figure~\ref{fig:limitstocks}). This provides information on order book imbalance that can be helpful for the trader to decide on the optimal time to enter or to exist the market (see Figure~\ref{fig:limitstocks}). It is observed from Figure~\ref{fig:limitstocks} that the bid-ask spread is at least twice the difference between quotes at successive depths. Thus the slope of the book is steeper closer to the best quotes. \\
	\begin{figure}[!ht]
	   \centering
	   \includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/limitstocks.png} 
	\caption{The Limit Order Book for Stocks. (A) Plots the cross-sectional average (across with tick$=$FF 0.1) of the time-series averages of the five best ask and bid quotes and their associated depth. (B) plots the cross-sectional average (across stocks with tick$=$FF 1) of the time-series averages of the five best ask and bid quotes and their associated depth.\label{fig:limitstocks}}
	\end{figure}

\noindent\textbf{Order Flow:} The orders can be characterized as buyer or seller initiated and how aggressive they are. The aggressiveness is quantified by the size of the order. Most of the orders are small indicating that they could be part of a large parent orders. Both placement and cancellation of orders seem to decrease away from the best quotes. As the intra-day trading pattern follows typical diurnal pattern, both the depth and order flow must be adjusted for the time of the day. Some observations (stylized facts) worth noting are:
\begin{enumerate}[--]
\item Large (small) trades on one side of the market tend to be followed by large (small) trades on the same side. The same thing could be said about the new limit orders and cancellations as well. It is speculated that this may be due to traders reacting similarly to the same events or due to parent order splitting and automatic placement of child orders. \\

\item Cancellations on the buy side of the book are more frequent after market buy orders and the same for sell orders. This may be due to the fact that the large sell orders tend to convey negative information about the stock while the large buy orders convey positive information. Cancelations may also occur because of placement of some market orders are intended to probe the presence of any hidden orders. \\

\item Conditioning on the state of the book by size of bid-ask spread and the depth, it is observed that trades are more frequent when the spread is tight but the new orders inside the quotes are more frequent when the spread is large. The changes in spread are mainly due to liquidity shocks. \\

\item Frequency of trades tends to be clustered because competing traders who monitor the market closely are likely to place the orders when they read the market in their favor. It is observed that the trading activity is more intense with the information flow. Also observed are the following stylized facts: when the spread is large after liquidity shocks, traders place their orders quickly to take advantage of time priority. Thus the spread reveals back to original level. The expected time interval is generally lower after large trades than after other trades whether the spread is large or not.
\end{enumerate}


Thus the study by Biasis et al. (1995)~\cite{spalt} provides a set of concrete measures that could be used to study the dynamics of the limit order book. Now we will delve into model formulations. 


One of the earlier models to appear in the econometric literature is by Lo, MacKinlay and Zhang (2002)~\cite{maczhang}; they used the data from Investment Technology Group (ITG) that contained time stamped information on each limit order from submission to cancellation or execution. With three possible paths for each submitted order, the associated (a) time-to-cancellation/modification, (b) time-to-first fill and (c) time-to-completion are tracked and models are developed for each path on both sides of the order. Because ITG largely deals with the institutional investors, the results apply only to a limited segment of the traders. The modeling approach is to get the execution times as the first-passage time to the limit price assuming that price follows a geometric Brownian model with a drift (Model 1.1):  
	\begin{equation}\label{eqn:dp(t)}
	dP(t)= \alpha \cdot P(t) \; dt + \sigma \cdot P(t) \; dW(t)
	\end{equation}
where $W(t)$ is a standard Brownian motion. A buy limit order with a price `$P_l$' is executed in the time interval $[t_0,t_0+t]$ only if $P_{\text{min}} \leq P_l$ and the probability is
	\begin{equation}\label{eqn:expprob}
	P_r(P_{\text{min}} \leq P_l \;|\; P(t_0)=P_0)= 1- \left(1 - \left(\dfrac{P_l}{P_0}\right)^{2\mu/\sigma^2}\right) \Phi\left[\dfrac{\ln(P_0/P_l) + \mu t}{\sigma \sqrt{t}}\right]
	\end{equation}
where $\mu=\alpha - \frac{1}{2} \sigma^2$ and $\Phi(\cdot)$ is the cumulative distribution function of the standard normal. 

Note (\ref{eqn:expprob}) can be alternatively stated as, if `$T$' denotes the limit order execution time, $F(t)=P(T \leq t \;|\; P_0)$ for buy orders and similarly for sell orders, $F(t)=p_r(P_{\text{max}} \geq P_l)$. To see if the model is appropriate for the data at hand compare the theoretical c.d.f. of $F(t)$ to empirical c.d.f. using the well-known result that these are uniformly distributed. Fix `$\tau$' as the fixed sampling interval and with $r_t=\ln(P_t)-\ln(P_{t-1})$, the estimates of $\mu$ and $\sigma^2$ are:
	\begin{equation}\label{eqn:sampleestm}
	\hat{\mu}= \dfrac{1}{N\tau} \sum_{j=1}^N r_j, \quad \hat{\sigma}^2= \dfrac{1}{N} \sum_{j=1}^N \dfrac{(r_j - \hat{\mu} \tau)^2}{\tau}
	\end{equation}
where `$N$' is the number of observations in the sample. 


The above First Passage Time (FPT) model was used for filled orders without taking into account that other orders that were cancelled or modified in that duration. The model's other limitations include not accounting for time priority, not including other relevant variables such as price volatility, spreads, etc.. The model's performance using the empirical cumulative distribution function is shown to be lacking. The model (\ref{eqn:expprob}) is expanded as
	\begin{equation}\label{eqn:cumexpmodel}
	F(t)=p_r(T_k \leq t \;|\; X_k,P_{lk}, S_k, I_k)
	\end{equation}
where $T_k$ is the execution of time of $k$ orders, $P_{lk}$ is the limit order price, $S_k$ is the size and $I_k$ is the side indicator. An alternative function, the hazard rate (briefly discussed in Chapter 2)
	\begin{equation}\label{eqn:hazard}
	h(t)=\dfrac{f(t)}{1-f(t)}= \dfrac{f(t)}{S(t)}
	\end{equation}
is found to be useful to operationalize and explain the modeling of survival rate of time-based events; Note $S(t)$ is called the survivor function. The censoring information ($\delta_i=1$ if observation `$i$' is censored) can be incorporated with $t_i$, $i$th realization of the random variable, $T$. It is assumed that the censoring mechanism is independent of the likelihood the limit order is executed. Using the generalized Gamma (defined in Chapter 2) as $f(t)$, the models are estimated.


The following variables are used as explaining variables:
\begin{enumerate}[--]
\item Distance between mid-quote and limit price.
\item Prior trade indicator for buyer or seller initiated.
\item Measures of liquidity.
\item Measures of market depth.
\item Measures that reflect change in trading activities. 
\end{enumerate}
It is shown that this model does fare better than FPT model to capture the execution times. But an important limitation is ``\dots censoring as a result of prices moving away from the limit price would be a violation of the underlying assumption since prices at the time of censoring are not included in $X_i$.'' We show in our analysis of Level III data, a key determinant for cancellation of an order is that price moving away from the limit price that the trader has desired. 


There are a number of studies that have looked into order book dynamics using models that arise from Point Processes. Bouchard, Mezard and Polters (2002)~\cite{bouchardmezard} investigate the interaction between order flow and liquidity; it is observed that the distribution of incoming limit order prices follow a power law around the current price and the overall shape of the book in terms of volume on both sides is rather systematic. Smith, Farmer, Gillemot and Krishnamunthy (2003)~\cite{smithfarm} and Farmer et al. (2004)~\cite{} study how the order flow influences price formation; the price impact of market orders is a function of touch price depth and spread size. Hewlett (2006)~\cite{} focuses on using LOB dynamics to find optimal liquidation strategies in foreign currency markets. 


To have a more complete and realistic picture of how the LOB evolves, we must consider `hidden liquidity'. Almost all exchanges allow traders to hide all or portions of their orders. The so called, ``iceberg order'' is split into several smaller parts and is queued along with the other orders, but only the displayed quantity is visible and is part of the market depth. When the order reaches the front of the queue only the displayed is executed. Several reports could be as high as 26\%. In the models discussed below, we will not address the hidden liquidity issue, which will be taken up in a later section.


Modeling of LOB dynamics has drawn on ideas from economics, physics, statistics and psychology. The approach taken in economics literature is to focus on the behavior of the traders and the dynamics is modeled as sequential games (Foucault (1999)~\cite{}, Parloys (1998)~\cite{} and Rosu (2009)~\cite{}). Others, such as researchers from physics, have treated order flows as random and statistical mechanics techniques are used to study the dynamics. Other studies, such as Parlour and Seppi (2008)~\cite{parseppi} and Bouchaud et al. (2009) are useful references for studies that come from economics point of view. We will review three models that are of recent origin. \\


\noindent\textbf{Cont, Stoikov and Talreja (2010)~\cite{contstoi}}: In this model of the limit order book, the number of limit orders at each price level in the book is taken to be a continuous-time Markov chain. The evolution of the order book through market orders, limit orders and cancellations is represented as a counting process. The model replicates the evolution of the events using independent Poisson processes. The study views LOB as a system of queues subject to order book events whose occurrences are modeled as a multidimensional point process. Before we state the specific questions and the models implications, we define certain useful quantities. 


It is taken that the price grid as $P(n)=\{1,2,\ldots,n\}$ multiples of a price tick. The number of outstanding orders in the book $|X_t^i|$ at price $i$, collectively, $X_t \equiv (X_t^1,\ldots,X_t^n)$ is taken to be continuous-time Markov chain; if $X_t^i<0$, then there are $-X_t^i$ bid orders at price `$i$' and if $X_t^i>0$, then there are $X_t^i$ ask orders at price $i$. Now we have,
	\begin{equation}\label{eqn:bestmidspread}
	\begin{split}
	\text{Best Ask Price: }& p_A(t)=\inf\{i \colon X_t^i>0\} \\
	\text{Best Bid Price: }& p_B(t)=\sup\{i \colon X_t^i<0\} \\
	\text{Mid Price: }& p_M(t)=(p_A(t)+p_B(t))/2 \\
	\text{Spread: }& p_S(t)=p_A(t)-p_B(t)
	\end{split}
	\end{equation}
The depth of the order book is stated relative to best bid and best ask on either side of the book. This way the model can be applied to order book for any equity subject to ever changing, best bid and best ask. Define
	\begin{flalign}\label{eqn:qaqb}
	&& Q_i^B(t)&= \begin{cases} X_{p_A(t)-i}(t), & 0<i<p_A(t) \\ 0, & p_A(t) \leq i <n \end{cases} && \notag \\
	\text{and} && \phantom{x} & \phantom{x} && \\
	&& Q_i^A(t)&= \begin{cases} X_{p_B(t)-i}(t), & 0<i<n-p_B(t) \\ 0, & n-p_B(t) \leq i <n \end{cases} && \notag
	\end{flalign}
Thus, $Q_i^B(t)$ and $Q_i^A(t)$ denote the number of buy orders at a distance `$i$' from ask and the number of sell orders at a distance `$i$' from bid, respectively. This representation highlights the shape (or depth) of the book relative to the best quotes on either side.


The following assumptions are made on the order arrivals: market buy or sell orders arrive at independent exponential times with rate, $\mu$. Limit buy or sell orders arrive at a distance of `$i$' ticks from the opposite best quote at independent exponential times with rate $\lambda(i)$. The cancellations of limit orders occur at a rate proportional to the number of outstanding orders, $\theta(i)X$. All these events are assumed to be mutually independent.


How the limit order is updated with the inflow of above events can be described as follows: for a state $x \in \mathbb{Z}^n$ and $1 \leq i \leq n$, let $x^{i \pm 1}=x \pm (0,\ldots,1,\ldots,0)$, where `1' denotes the change in the $i$th component. For example, a limit buy order at price level, $i<p_A(t)$ increases the quantity at level `$i$', from $x$ to $x^{i-1}$ with rate $\lambda(p_A(t)-i)$. Similarly, limit sell order arrived which changes the order book from $x$ to $x^{i+1}$ with rate $\lambda(i-p_B(t))$ for $i>p_B(t)$. For market buy order decreases at the ask price $i$ and hence $x \to x^{p_A(t)+1}$ with rate `$\mu$' and the sell order at the bid price, `$i$' will change the book status, $x \to x^{p_A(t)+1}$ with rate $\mu$. Cancellation of a buy order at price level, `$i$', will decrease the quantity at the rate $\theta(p_A(t)-i)|X_p|$ for $i<p_A(t)$ and the sell order will decrease the quantity at the rate of $\theta(i-p_B(t))|X_p|$ for $i>p_B(t)$.


It is assumed that the limit order arrival rate $\lambda(i)$ follows a power law
	\begin{equation}\label{eqn:powerlaw}
	\lambda(i)=\dfrac{\kappa}{i^\alpha}
	\end{equation}
which is confirmed by several empirical studies (Farmer (2002)~\cite{} for example). The empirical estimates of the parameter are based on the following quantities: $s_m$ is the average size of the market orders, $s_l$ is the average size of the limit orders and $s_c$ is the average size of the cancelled orders. Also let $N_l(i)$ be the total number of limit orders that arrived at a distance `$i$' from the opposite best quote and $T_*$ is the total trading time in minutes and $N_m$ is the number of market orders during the sam time. Then 
	\begin{equation}\label{eqn:hatlambdant}
	\hat{\lambda}(i)= \dfrac{N_l(i)}{T_*}, \quad 1 \leq i \leq 5
	\end{equation}
where $\hat{\lambda}(i)$ is extrapolated beyond five positions using the power law in (\ref{eqn:powerlaw}) simply by minimizing $\sum_{i=1}^5 (\hat{\lambda}(i)- \frac{\kappa}{i^\alpha})^2$, over `$\kappa$' and `$\alpha$'. The arrival rate is estimated as:
	\begin{equation}\label{eqn:hatnmt}
	\hat{\mu}=\dfrac{N_m}{T_*} \cdot \dfrac{s_m}{s_l}
	\end{equation}
The cancellation rate as noted earlier is defined as proportional to the number of order at that price level,
	\begin{equation}\label{eqn:hatthetacase}
	\hat{\theta}(i)=
	\begin{cases}
	\dfrac{N_l(i)}{T_*Q_i} \cdot \dfrac{s_c}{s_i}, & i \leq 5 \\
	\hat{\theta}(5), & i>5
	\end{cases}
	\end{equation}
It is understood that the cancellation is not due to executing market orders.


While these descriptives are easy to compute and are intuitive, but the main interest in modeling high frequency dynamics of order book is to predict short-term behavior of various key quantities that were identical earlier that may help in algorithmic trade executions. Some relevant questions are as stated before, given the state of the order book, what is the probability that mid-price will move up, what is the probability of executing both buy and sell order at the best quotes before the price changes etc.. These conditional probabilities are evaluated using Laplace transforms.


We present some key results in Cont et al. (2010)~\cite{contstoi}. The probability of queue going up when there are no orders in the queue, for $1 \leq d \leq 5$, given that the best quotes are not changing is
	\begin{equation}\label{eqn:queuecon}
	p_{\text{up}}^d(m)=
	\begin{cases}
	\dfrac{\hat{\lambda}(d)}{\hat{\theta}(d)m+\hat{\lambda}(d)+\hat{\mu}}, & d=1 \\
	\dfrac{\hat{\lambda}(d)}{\hat{\theta}(d)m+\hat{\lambda}(d)}, & d>1.
	\end{cases}
	\end{equation}
Other questions such as the probability that the mid price goes up when the spread $\geq 1$ etc. are based on the following quantities:
\begin{itemize}
\item Probability of a market buy order
	\begin{equation}\label{eqn:probmarketbuy}
	\dfrac{\mu^a}{\mu^b+\mu^a+\sum_j (\lambda_B(j)+\lambda_A(j)+\theta(j) Q_j^A(t)+\theta(j)Q_j^B(t))}
	\end{equation}
\item Probability of a limit buy order $d$ ticks away from the best ask
	\begin{equation}\label{eqn:problimitbuytick}
	\dfrac{\lambda_B(d)}{\mu^b+\mu^a+\sum_j(\lambda_B(j)+\lambda_A(j)+\theta(j)Q_j^A(t)+\theta(j)Q_j^B(t))}
	\end{equation}
\item Probability of a cancel buy order $d$ ticks away from the best ask
	\begin{equation}\label{eqn:probcanceltick}
	\dfrac{\theta(d)Q_d^B(t)}{\mu^b+\mu^a+\sum_j(\lambda_B(j)+\lambda_A(j)+\theta(j)Q_j^A(t)+\theta(j)Q_j^B(t))}
	\end{equation}
\end{itemize}
The model was evaluated using data sets from Tokyo Stock Exchange. The model is shown to capture realistic features of the order book profile.
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/intertime.png} 
   	\caption{Distribution of inter-arrival times of market orders for stock BNPP.PA (Chakraborti et al. 2011). \label{fig:intertimefig}}
	\end{figure}

The use of Poisson processes to model the flows of limit orders, market orders and cancellations makes the method analytically tractable. The model captures the steady-state shape of the order book (although there may be other distributions that may be fit better besides Poisson, see Figure~\ref{fig:intertimefig}) but it may not be useful for predicting short-term behavior that may be more relevant for the traders. The assumption of Poisson process results in that the intensity of arrivals and cancellations does not depend on the state of the order book which is somewhat unrealistic given the feedback loop relationship between the behavior of the market participants and the history of the order book. Recent works, by Zhao (2010)~\cite{} and Abergel (2010)~\cite{} show that the memory-less property is not empirically valid. Orders tend to be clustered due to dependencies between liquidity taking and liquidity providing and also due to algorithmic execution of parent order that is split into numerous child orders. Also, the assumption that all orders are of the same size is too simplistic. 


Zhao (2010)~\cite{} proposes a model based on marked point process when the mark represents order types, price, size etc.. The joint modeling also assumes that the order flow is self-exciting, i.e. new orders or cancellations occur in an orderly point processes with an intensity function that depends on the history of the limit order book. The model is somewhat difficult to estimate and does not fully capture the empirical results such as volatility clustering etc.. \\

\noindent\textbf{Hawkes Process:} The features of volatility clustering and the significant autocorrelations in durations between order arrivals and significant cross-correlation of arrival rates across various event types are better captured by multi-dimensional Hawkes process. For a given $M$-dimensional point process, let $N_t=(N_t^1,\ldots,N_t^M)$ denote the associated counting process and the Hawkes process is characterized by intensities, $\lambda^m(t), m=1,\ldots,M$ as
	\begin{equation}\label{eqn:lambdamdoub}
	\begin{split}
	\lambda^m(t)&= \lambda_0^m(t) + \sum_{n=1}^M \int_0^t \sum_{j=1}^P \alpha_j^{mn} e^{-\beta_j^{mn}(t-s)} dN_s^n \\
	&=\lambda_0(t) + \sum_{n=1}^M \sum_{t_j<t} \sum_{j=1}^P \alpha_j^{mn} e^{-\beta_j^{mn}(t_j -t_i^n)}
	\end{split}
	\end{equation}
where the number of exponent kernels, $P$, is fixed and $t_i^n$ is the $i$th jumping time of the $m$th variate. The scale and decay parameters, $\alpha^{mn}$ and $\beta^{mn}$ express the influence of the past events $t_i^n$ of type `$n$'. The baseline model in (\ref{eqn:lambdamdoub}) does not incorporate the effect of bid-ask spread on order flow. It is shown in Anderson, Cont and Vinkovskaya (2010)~\cite{} that $\alpha$ and $\beta$ parameters do depend on the bid-ask spread. A simulated Hawkes process is given in Figure~\ref{fig:hawkes}. The main characteristic of the Hawkes process is that intensity goes up at each event and decays exponentially between events. 
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.9\textwidth]{chapters/chapter6/figures/hawkes.png} 
   	\caption{Simulated two-dimensional Hawkes process (Toke 2011). \label{fig:hawkes}}
	\end{figure}

The evolution of the order book is driven by six different intensity functions, but the model changes with the value of the spread. The base intensity and the decay rates are all assumed to be functions of the spread. The model is quite complex and requires the estimation of a large number of parameters, which in turn requires vast amount of data for calibration. 


The mathematical framework was developed in Hawkes (1971)~\cite{} and was expanded in Hawkes and Oakes (1974)~\cite{}. The application of Hawkes process in finance is of recent origin: see Toke (2011)~\cite{} or Bacry et al. (2011)~\cite{}. We will briefly discuss the likelihood estimates of the model in (\ref{eqn:lambdamdoub}). First, we want to observe for a Poisson process, the intensity function $\lambda(t)=\lambda_0$, a constant. The log-likelihood of the model,
	\begin{equation}\label{eqn:loglikemod}
	\ln \mathcal{L}(\{t_i\}_{i=1,2,\ldots,N}) = \sum_{m=1}^M \ln \mathcal{L}^m(\{t_i\})
	\end{equation}
where
	\[
	\ln \mathcal{L}^m(\{t_i\})= T - \sum_{i=1}^N \sum_{n=1}^M \dfrac{\alpha^{mn}}{\beta^{mn}} (1- e^{-\beta^{mn}(T-t_i)}) + \sum_{t_i^m} \ln[ \lambda_0^m(t_i^m) + \sum_{n=1}^M \alpha^{mn} R^{mn}(l) ]
	\]
and 
	\[
	R^{mn}(l)= \sum_{t_\kappa^n t_l^m} e^{-\beta^{mn}(t_l^m-t_\kappa^n)}
	\]
is the cumulative decay function. Using the Multiplicative Random Time Change Theorem (see Meyer (1971)~\cite{}) that states that with a certain transformation of the variables, the Hawkes process can be changed to a unit rate homogeneous Poisson process. Transforming the time variable `$t$' into `$\mathcal{T}$', where
	\begin{equation}\label{eqn:calt}
	\mathcal{T}= \int_0^t \lambda(s) \; ds
	\end{equation}
Hawkes process becomes a Poisson process with unit rate. Thus
	\begin{equation}\label{eqn:diffcalt}
	\mathcal{T}_i - \mathcal{T}_{i-1}= \Lambda(t_{i-1},t_i) = \int_{t_{i-1}}^{t_i} \lambda(s) \; ds
	\end{equation}
is exponentially distributed. 


More generally in the `$M$' dimensional multivariate case,
	\[
	\begin{split}
	\Lambda^m(t_{i-1}^m,t_i^m)&= \int_{t_{i-1}^m}^{t_i^m} \lambda_0^m(s) \; ds + \int_{t_{i-1}^m}^{t_i^m} \sum_{n=1}^M \sum_{t^n<t_{i-1}^m} \alpha^{mn} e^{-\beta^{mn}(s-t^n)} \; ds \\
	&+ \int_{t_{i-1}^m}^{t_i^m} \sum_{n=1}^M \sum_{t_{i-1}^m<t^n<s} \alpha^{mn} e^{-\beta^{mn}(s-t^n)} \; ds
	\end{split}
	\]
will follow exponential distribution. The $\Lambda^m(t_{i-1}^m,t_i^m)$ are known as compensators and can be verified empirically if it follows exponential distribution. 


\subsection{Application of a Hawkes process}


We want to illustrate the model with an application. We will first look at the statistical properties of the data and then look at the results of fitting one and two dimensional Hawkes processes to it. Our findings show that a two dimensional model based on Hawkes processes performs considerably better than a model based on two independent Poisson Processes. This provides strong evidence of the fact that the two key features of Hawkes processes (path dependency of the order flow and the possibility of modeling the interaction between the dimensions) are capable of capturing and replicating some of the key features of the empirical data. Moreover, there is evidence of significant and asymmetric interplay between the buy and the sell sides for the Limit Orders and evidence of limited interplay between the two sides when it comes to Market Orders. Finally, a study of the statistical properties of the orders showed a complex of alternating symmetric and asymmetric behavior of the LOB. 


The data at hand is INET data for XOM (Exxon Mobil) for the 1st of September 2010. The first step was to look at the submission frequency of the Limit Orders during the trading day. Figure~\ref{fig:freqsubmitarrivals} shows such frequency plot and we can see how in the first hour a half and in the last half an hour of the trading day there is a much higher submission frequency (with peaks of 25/30 orders submitted per second) than during the rest of the day (around 5--10 orders per second).
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/freqsubmit.png} 
   	\caption{Frequency of Limit Order submission for 09/01/2010 (time in minutes after market opening). \label{fig:freqsubmitarrivals}}
	\end{figure}


This means that if we choose to look at the Limit Order flow with a model that doesn't allow for a varying baseline intensity, we will have to drop these two periods of increased trading activity and keep the data for only the middle portion of 6 hours of the trading day.


We then looked at the data for the central portion of 6 hours of the trading day and found that market orders are just a function of Limit Orders. There were almost 90,000 Limit Orders submitted during that period of the day, compared to the only about 4,000 Market Orders. Similarly, there is an imbalance in the side of the order submission, with around 42,000 Limit Orders submitted on the Sell side compared to the 48,000 submitted on the Buy side (about 18\% more). This side-imbalance is also present in the Market Order submission although not that strongly: 1,882 Market Orders submitted on the Sell side compared to the 2,107 orders submitted on the Buy side (only about 12\% more). 
	\begin{table}
	\centering
	\caption{XOM data for 09/01/2010 \label{tab:xom}}
	\begin{tabular}{llll} 
	& Limit Orders & Market Orders & Total \\ \hline
	Buy & 48,541 & 2,107 & 50,648 \\ 
	Sell & 41,194 & 1,882 & 43,076 \\
	Total & 89,735 & 3,989 & 93,724
	\end{tabular}
	\end{table}
This shows how, on this trading day, most of the ``action'' was occurring on the Buy Side of the book which could mean that the markets were confident in an increase of the price of XOM (in line with the historical performance of the stock for that day).


Our next step was to re-construct the Limit Order book from the order flow so to look at the life of the Limit Orders after their submission. We first looked into how many of the submitted Limit Orders get executed and, when they do, in how many fills. We found Table~\ref{tab:LOexec} that only about 6.5\% of all submitted LOs get at least partially filled with the percentage dropping to only about 6\% for those LO that actually get completely executed. Also, out of the LO that are completely filled nearly 90\% of them is filled in just one execution. This allows us to say that the magnitude of the LOs is comparable to that of the Market Orders, given that nearly all of them require only one Market Order to fill it completely. It is also interesting to note how few of the LOs that are submitted actually get executed. 
	\begin{table}
	\centering
	\caption{LO executions and percentage breakdown by number of fills required \label{tab:LOexec}}
	\begin{tabular}{cccc}
	Number of LO & \% at least partially fill & \% completed in one fill & \% completely fill \\
	89, 735 & 6.57 & 5.35 & 6.15
	\end{tabular}
	\begin{tabular}{ccccccc}
	1 & 2 & 3 & 4 & 5 & 6 & $\geq$ 7 \\ \hline
	87.14 & 10.83 & 1.34 & 0.37 & 0.13 & 0.06 & 0.13
	\end{tabular}
	\end{table}


This means that either very few LO are actually submitted close to the market (hence have a chance to get executed) or that many of them don't stay in the book long enough to get executed. This led us to look into the life-time of the LOs and, more specifically, at their cancellation and execution times. We focused on how long, on average, for an order to be either not filled or partially filled LO stayed in the book before getting cancelled and at how long did it take for a LO to be either filled for the first time or completely filled. Results are given in Table~\ref{tab:meanlo}.
	\begin{table}
	\centering
	\caption{Mean LO cancellation and execution times (in seconds) \label{tab:meanlo}}
	\begin{tabular}{cccc}
	\multicolumn{2}{c}{No Fills} & \multicolumn{2}{c}{Partial Filles} \\ \hline
	Buy Orders & Sell Orders & Buy Orders & Sell Orders \\ \hline
	177.8 & 250.5 & 46.1 & 63.0 \\ \hline
	\multicolumn{2}{c}{First Fill} & \multicolumn{2}{c}{Completion} \\ \hline
	 25.3 & 56.2 & 25.6 & 57.6
	\end{tabular}
	\end{table}

In this particular case, LOs stay in the book for much longer if they are on the sell side than if they are on the buy side. Orders that have never been filled are cancelled after 250 seconds if they are on the sell side compared to 177 seconds if they are on the buy side. Similarly, a partially filled LO on the sell side is cancelled after 63 seconds compared to 46 seconds if it's on the other side of the book. Also, if we look at the time it takes for a LO to be filled for the first time we see that that happens after about 56 seconds on the sell side compared to only 25 seconds on the buy side. Finally, for the LO that do get completely filled, it takes on average 1 minute for that to happen if the order is on the sell side compared to only 25 seconds if the order is on the buy side. This life-time difference for LOs on the two opposite sides of the book is consistent with what we saw earlier in the imbalance of the LO and MO submission. In fact, in this case as well we see how the buy side appears to be the more active side of the book. The shorter execution times for the orders on the buy side could be caused by either more aggressive pricing or by the price movements of the markets while the shorter lifespans and the higher number of orders on that side seem to indicate the use of more active trading strategies. However, there is another interesting observation that can be made. We see that on average a sell LO that is filled for the first time (but that doesn't get completely filled), is cancelled after about 7 seconds, compared to the 20 seconds that it would take had the order been on the buy side. This means that on average it takes three times longer for a partially (and never completely) filled order to be cancelled if it is on the buy side (which is the more active side) that if it is on the sell side (which is the less reactive side). The asymmetry between buy and sell side at the aggregated level has been noted in the literature.


The next step was to observe changes in the behavior of the book when moving further away from the market. We looked into the order submission and cancellation frequencies as a function of distance from the market price. Figure~\ref{fig:canfreq} and Figure~\ref{fig:freqsubmit1} show that most LO are submitted and cancelled at the market (respectively, 40\% and almost 30\%) and that the rates drop sharply with each price level further away from it. This supports the conclusion that the very small percentage of executed LO is not caused by the fact that most LO are submitted far away from the market and hence don't get the chance to get executed. We can also see how approximately 70\% (96\%) of all Limit Orders is placed in the top 5 (20) levels of the book and that 69\% (96\%) of all cancellations also occurs in the top 5 (20) levels. This a first indication of the fact that Level III data offers more information than Level II since with the top 5 levels of the book we were only able to capture around 70\% of all the occurring events. However, this also indicates that there is no need to use all the information provided in Level III data since by looking at only the top 20 levels of the book we are still able to capture nearly all of the occurring events. Both plots show a very similar behavior for the buy and sell side which led us to assume an almost symmetric behavior of the book. This assumption was later tested and confirmed at a 99\% confidence level with a two-sided Kolmogorov-Smirnov Test. 
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/subfreqnear.png} 
   	\caption{Submission frequencies--Distance near touch price \\ Kolmogorov-Smirnov Test Statistics$=0.61 \to$ fail to reject null at 1\% sig. level \label{fig:subfreqnear}}
	\end{figure}
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/canfreqnear.png} 
   	\caption{Cancellation Frequencies--Distance from near touch price \\ Kolmogorov-Smirnov Test Statistic$=0.83\to$ fail to reject null at 1\% sig. level \label{fig:canfreqnear}}
	\end{figure}


Better understanding what happens to the LOs once they enter the book is key in developing a more accurate way of choosing when to submit a LO or a MO. For this reason we also looked at the cancellation frequencies as a function of position in the queue and we found that (Figure~\ref{fig:canfreq}) most of the cancellations occur when the LO are in 4th or 5th position in the queue. In this case as well, we carried out a test of the assumption of a symmetric behavior of the book which confirmed previous similar findings. However, it would be more interesting to look at the cancellation frequencies as a function of overall distance from the market (as a measure of distance from possible execution). 
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/canfreq.png} 
   	\caption{Cancellation Frequencies---position in queue. \label{fig:canfreq}}
	\end{figure}


With two more trading days (3rd and 9th of September 2013) data available, we are able to study the robustness of the above results. The submission and cancellation frequencies as a function of relative price which were symmetric for the 1st of September were not symmetric anymore on the 3rd of September. In this trading day, Figure~\ref{fig:freqsubmit1}, the peak of activity on the buy side occurred 12 price levels away from the market. This seems to suggest that on the 3rd of September the markets were betting that the price of XOM would drop in the foreseeable future, possibly reacting to some new event. A closer investigation of that time period revealed in the previous days the announcement by Exxon Mobil of the plan of closing a refinery which then led to a drop in the price shortly after 09/03/2010.
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/losubcanfreq.png} 
   	\caption{LO submission and cancellation frequencies. \label{fig:losubcanfreq}}
	\end{figure}


A second interesting difference was in the amount of volume on the two sides of the book (Figure~\ref{fig:losubcanfreq}). Across the 3 days there was a significant volume imbalance with considerably more volume on the sell side than on the buy side but the amount of imbalance between the two sides changes significantly across the three days. Overall there is no explanation as to why there would be such a strong volume imbalance in favor of the sell side other than some kind of temporary anomaly. These findings seem to point out the fact that the shape and behavior of the LOB change dramatically across different days and that, in order to capture some kind of more general/average behavior of the book, many more days of data are required. 
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/freqsubmit.png} 
   	\caption{Frequency of Limit Order submission for 09/01/2010 (time in minutes after market opening). \label{fig:freqsubmit1}}
	\end{figure}
	\begin{figure}
	\centering
	\begin{subfigure}
	  \centering
	  \includegraphics[width=.4\linewidth]{chapters/chapter6/figures/timevol1.png}
	\end{subfigure}%
	\begin{subfigure}
	  \centering
	  \includegraphics[width=.4\linewidth]{chapters/chapter6/figures/timevol1.png}
	\end{subfigure}
	\caption{Frequency of Limit Order submission for 09/01/2010 (time in minutes after market opening). \label{fig:freqsubmit2}}
	\end{figure}


\subsection{One-Dimensional Models}


We started by building a one dimensional model for the Limit Orders submitted on the buy side and one for those submitted on the sell side. Similarly, we build a one dimensional model for the Market Orders submitted on each side of the book. In the one dimensional case, the intensity function driving the Hawkes process is of the form
	\begin{equation}\label{eqn:lambda6}
	\lambda(t)= \lambda_0 + \alpha \sum_{t_i<t} e^{-\beta(t-t_i)}
	\end{equation}
with $\lambda_0$ indicating the baseline intensity, $\alpha$ indicating the jump in the intensity after the occurrence of an event and $\beta$ indicating the rate of exponential decay of the intensity after the occurrence of an event.


Table~\ref{tab:limmodbuy} and Table~\ref{tab:limmodsell} show the results of the MLE estimation of the parameters of the one dimensional models for the Limit Orders on the two sides of the book. The difference in the values of the estimates of the parameters for the two sides of the book (strongest on the 9th and weakest on the 1st of September) indicates that there is a level of asymmetry between these two sides. Also, even though the magnitude of the values of the parameters is the same for all three days (on each side of the book) there is still some variation between them, especially when we look at the model for the buy side. This seems to suggest that the behavior of the book can change considerably from day to day and that a considerable amount of data might be necessary in order to capture some kind of general behavior. 
	\begin{table}
	\centering
	\caption{1-D Limit Order Model (buy side) \label{tab:limmodbuy}}
	\begin{tabular}{c|ccc} 
		& $\lambda$ & $\alpha$  & $\beta$ \\ \hline
	09/01/2010 & 0.008108431 & 1.421767060 & 1.435094466 \\
	09/03/2010 & 0.006127003 & 1.290012415 & 1.299564704 \\
	09/09/2010 & 0.002341542 & 1.023410145 & 1.026757239
	\end{tabular}
	\end{table}
	\begin{table}
	\centering
	\caption{1-D Limit Order Model (sell side) \label{tab:limmodsell}}
	\begin{tabular}{c|ccc} 
		& $\lambda$ & $\alpha$ & $\beta$ \\
	09/01/2010 & 0.002055786 & 1.071071139 & 1.073989940 \\
	09/03/2010 & 0.002342963 & 0.983678355 & 0.986999404 \\
	09/09/2010 & 0.006123845 & 0.946420813 & 0.955774394
	\end{tabular}
	\end{table}


One of the advantages of having chosen an exponential decay for the intensity function of the process, becomes apparent when we analyze the meaning of these parameters. Using a well-known property of exponentially distributed variables, we can tell the half-life of the excitation effect caused by the occurrence of an event. In the specific, in our one-dimensional models we find that, on average, half of the excitation effect caused by the occurrence of an event is dissipated after about 0.7 seconds ($\frac{\ln 2}{\beta} \approx$ half-life). Also, the small estimated values for $\alpha$ indicate that the occurrence of an event has a very small impact on the likelihood of another event occurring. This seems to suggest that there is a weak self-excitation effect in the LO process when modeling it with a one-dimensional model. 


We then build, in a similar fashion, the two one-dimensional models for the flow of buy and sell Market Orders for all three days and obtained the following parameter estimation: 
	\begin{table}[!ht]
	\centering
	\caption{1-D Market Order Model (buy side) \label{tab:marketorderbuy}}
	\begin{tabular}{c|ccc} 
		& $\lambda$ & $\alpha$ & $\beta$ \\ \hline
	09/01/2010 & 0.0238743 & 7.3187478 & 19.8477514 \\
	09/03/2010 & 0.01450873 & 3.38168999 & 7.70581048 \\
	09/09/2010 & 0.0267254 & 4.8818834 & 13.5427254
	\end{tabular}
	\end{table}
	\begin{table}[!ht]
	\centering
	\caption{1-D Market Order Model (sell side) \label{fig:marketordersell}}
	\begin{tabular}{c|ccc} 
		& $\lambda$ & $\alpha$  & $\beta$ \\ \hline
	09/01/2010 & 0.02083999 & 9.38842281 & 24.55777564 \\
	09/03/2010 & 0.01616096 & 6.64370599 & 16.68090519 \\
	09/09/2010 & 0.0239992 & 8.2180945 & 25.0115980
	\end{tabular}
	\end{table}
The first thing that is obvious is the asymmetry between the buy and the sell sides. Nevertheless, for the Market Orders they asymmetry appears to be much more significant that it was for the Limit Orders, given the much bigger differences in the values of the estimated parameters. Also, for Market Orders we see that the occurrence of each event seems to have a much stronger impact on the likelihood of occurrence of future events than it was the case for Limit Orders. In fact, the values of $\alpha$ in Table~\ref{tab:marketorderbuy} and Table~\ref{fig:marketordersell} are considerably higher than those we saw in Table~\ref{tab:limmodbuy} and Table~\ref{tab:limmodsell}. Similarly, the values of $\beta$ are also much larger in the Market Order models than they were in the Limit Order models which means that the half-life of the excitation effect is much shorter for Market Orders (0.03 seconds vs. 0.7 seconds) than for Limit Orders. These differences in the results of the estimations are not that surprising if we consider what we saw in Table~\ref{tab:xom} for order submissions. Market Orders are submitted in much fewer numbers than Limit Orders which explains why even though the occurrence, such self-excitation has a very short lifetime. The significant increase in the chances of another Market Order occurring given that one has just occurred (even through for a very short time), might seem contradicting the fact that very few Market Orders actually occur. However, what can be inferred is that Market Orders depend strongly from the occurrence of other Market Orders and that they tend to cluster around submissions. 


\subsection{An extension}


An important limitation of this basic Hawkes Process model is that each event has the same impact on the intensity function. This implies that each event carries the same amount of information in the process. However, it is easy to imagine that a large LO would carry much more information about future price changes than a small one and this should be accounted for in the model. We include order size in the intensity function by scaling the size of the jump $\alpha$ in the value of the intensity by the ratio $\frac{w_i}{\overline{w}_l}$, where $w_i$ is the size of the LO and $\overline{w}_l$ is the average LO size up to that point. The intensity function for this ``extended'' one-dimensional model becomes
	\[
	\lambda(t)= \lambda_0 + \alpha \sum_{t_i<t} \dfrac{w_i}{\overline{w}_l} e^{-\beta(t-t_i)}
	\]
We then compared the performance of this ``size-adjusted'' model with the ``basic'' one by using the before mentioned \emph{Multivariate Random Time Chance} Theorem and looking at the Q-Q plot of the compensators for the two models. Figure~\ref{fig:lobuysideadj} and Figure~\ref{fig:losellsideadj} show how in both case (buy and sell Limit Orders) adjusting for size doesn't improve the fit of the model. This result is somewhat counter-intuitive given that more than 70\% of all Limit Orders are of size 100 shares and that this should imply that any deviation from this size explanation is that trading strategies are successful in concealing the true intension of the traders and that there is no significant information left in the size of the LO once that the strategies are implemented and the orders are submitted. 
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/lobuysideadj.png} 
   	\caption{LO--buy side with size adjustment and without. \label{fig:lobuysideadj}}
	\end{figure}
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/losellsideadj.png} 
   	\caption{LO--sell side with size adjustment and without. \label{fig:losellsideadj}}
	\end{figure}


\subsection{Two-Dimensional models}


Our next step was to build two-dimensional models that would simultaneously model the buy and sell sides of the book and with two separate (yet interacting) intensity functions. The intensity functions for this kind of model become
	\[
	\begin{split}
	\lambda^B(t)&= \lambda_0^B + \int_0^t \alpha^{BB} e^{-\beta^{BB}(t-u)} \;dN_u^B + \int_0^t \alpha^{BB} e^{-\beta^{BS}(t-u)} \;dN_u^S \\
	\lambda^S(t)&= \lambda_0^S + \int_0^t \alpha^{SB} e^{-\beta^{SB}(t-u)} \; dN_u^B + \int_0^t \alpha^{SS} e^{-\beta^{SS}(t-u)} \;dN_i^S
	\end{split}
	\]
and we have 5 parameters for each dimension of the model for a total of 10 parameters across the two dimensions (buy and sell). The two additional parameters in each dimension account for the cross-excitation effect between the two dimensions. In our case, $\alpha^{BS}$ tells us the increase in the likeliness of a LO occurring on the buy side after the occurrence of a LO on the sell side, while $\beta^{BS}$ tells us the rate of decay of the buy side intensity after the occurrence of a LO on the sell side (and vice-versa for $\alpha^{SB}$ and $\beta^{SB}$). We then used MLE to estimate the parameters of the model and we can make several remarks about the results (Table~\ref{tab:2dimlomodel}).
	\begin{table}
	\centering
	\caption{2-Dimensional LO model \label{tab:2dimlomodel}}
	\begin{tabular}{lllll}  
	$\lambda^B=2.480 \cdot 10^{-5}$ & $\alpha^{BB}=14.386$ & $\beta^{BB}=31.517$ & $\alpha^{BS}=0.303$ & $\beta^{BS}=0.464$ \\ \hline
	$\lambda^S=2.677 \cdot 10^{-5}$ & $\lambda^{SS}=15.657$ & $\beta^{SS}=37.299$ & $\alpha^{SB}=0.149$ & $\beta^{SB}=0.312$ \\ 
	\end{tabular}
	\end{table}
	
	
There appears to be some asymmetry in the cross-excitation effects with the occurrence of an event on the sell side having a stronger impact on the likeliness of occurrence of an event on the buy side rather than the other way round ($\alpha^{BS}>\alpha^{SB}$). On the other hand though, since $\beta^{BS}<\beta^{SB}$, the effect on the sell side of an occurrence on the buy side is more persistent than that of an event on the buy side on the sell side (2.22 seconds vs. 1.49 seconds).
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/asymcross.png} 
   	\caption{Asymmetry in cross-excitation effect. \label{fig:asymcross}}
	\end{figure}
The self-excitation components of the model are rather similar for both dimensions and it is interesting to point out the very short persistence of the self-excitation effect in both cases (about 0.02 seconds).


In order to evaluate whether the two key features of a model based on Hawkes processes (path dependency of the order flow and the possibility of modeling the relation between the various dimensions) are really helpful in improving the performance of the model, we decided to compare the performance of our model to that of a bi-dimensional model based on two independent Poisson Processes (which by definition of Poisson process cannot account for any dependency in the order flow and by construction assume independence between the two dimensions). The results proved to be very encouraging with a remarkably better fit to the empirical data for the Hawkes Process based model (Figure~\ref{fig:4hawkes6}).
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/4hawkes6.png} 
   	\caption{Top--Fit of Hawkes Process (buy \& sell); Bottom--Fit of Poisson Process (buy \& sell). \label{fig:4hawkes6}}
	\end{figure}


Following a similar procedure, we build a bi-dimensional model for the Market Orders and performed MLE to estimate the parameters. The results (Table~\ref{tab:2dimmomod}) showed very weak and symmetric cross-excitation between the dimensions which, however, turns out to be very persistent (141 seconds for the half-life of the effect of buy on sell and 215 seconds for that of sell on buy). The self-excitation effect is comparable across the two dimensions and is also very short lived (with a half-life of about 0.02 seconds).
	\begin{table}
	\centering
	\caption{2-Dimensional MO model \label{tab:2dimmomod}}
	\begin{tabular}{lllll}  
	$\lambda^B=2.701 \cdot 10^{-5}$ & $\alpha^{BB}=11.793$ & $\beta^{BB}=36.153$ & $\alpha^{BS}=0.0037$ & $\beta^{BS}=0.0049$ \\
	$\lambda^S=3.451 \cdot 10^{-5}$ & $\alpha^{SS}=12.454$ & $\beta^{SS}=35.063$ & $\alpha^{SB}=0.0017$ & $\beta^{SB}=0.0032$
	\end{tabular}
	\end{table}
	

Finally, we compared the performance of our model to that of the bi-dimensional Poisson Process. Similarly to the LO case, the model at hand significantly outperforms the Poisson Process one for both dimensions. 
	\begin{figure}[!ht]
   	\centering
   	\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/4fig.png} 
   	\caption{Top--Fit of Hawkes Process (buy \& sell); Bottom--Fit of Poisson Process (buy \& sell). \label{fig:4fig6}}
	\end{figure}


\subsection{Limitations and findings}


There are some important considerations to be made based on our analysis. The first issue is related to the cleaning of the data that was necessary in order to adapt it to our needs. In fact, Hawkes processes are ``simple'' processes which means that they don't allow for more events to occur simultaneously. Unfortunately, in the INET data it is quite common to encounter clusters of 10/20 events reported with the same timestamp. This is typical of high frequency data due to the approximation with which events are often reported and to the obvious limitation of the chosen time scale (e.g., milliseconds). In our case we decided to keep only the first event of each cluster, dropping all the others. A possible alternative used in the literature is to simply uniformly distribute the events from the clusters across the time interval given by the occurrence of the cluster and that of the next event. However, this approach could introduce bias in the parameter estimation phase. In fact, the clustering of events by itself is of interest.


Also, an important limitation of the bi-dimensional Hawkes Process model is that it is very computationally intense. Evaluating the 5 parameters for one of the two intensity function using data from only one trading day took almost 48 hours. It becomes clear that in order to evaluate the parameters of a model using data for a longer time period of if evaluating the parameters for a model with higher dimension (hence with more parameters) will require considerably more computational power. 















\section{Models for Level II and Level III data}
\section{Estimation of Hidden Orders}
\section{Volume Imbalance and Other Indicators}
\section{Hidden Markov Models (HMM) for dynamic market microstructure:  Estimation of Parameter and States}
\section{Appendix:  Adaptive Particle Filters in HMM}
\section{Supplements and Problems} 